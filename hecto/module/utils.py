from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision import datasets
import torch
import os
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
import torch.nn.functional as F
from tqdm import tqdm
import numpy as np
from torchvision.utils import save_image
from torchvision.datasets import ImageFolder



def evaluate(model, data_loader, device, cce):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = cce(outputs, labels)
            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    acc = 100 * correct / total
    avg_loss = running_loss / len(data_loader)
    return avg_loss, acc

def test(model, test_path, transform, device):
    test_data = datasets.ImageFolder(root=test_path, transform=transform)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    model.eval()
    predictions = []     # ë¶„ë¥˜ ê²°ê³¼

    with torch.no_grad():
        for inputs, _ in test_loader:  # í…ŒìŠ¤íŠ¸ì…‹ ë¼ë²¨ì€ ë¬´ì‹œ
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            predictions.extend(preds.cpu().numpy())
    return test_data, predictions

def save_softmax_submission(model, test_path, transform, device, class_names, output_csv="submission.csv"):
    # test ë°ì´í„°ì…‹ (í´ë˜ìŠ¤ í´ë” ì—†ì´)
    test_dataset = TestImageDataset(test_path, transform)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    model.eval()
    results = []
    ids = []
    filenames = []

    all_probs = []

    with torch.no_grad():
        for imgs, fnames in tqdm(test_loader):
            imgs = imgs.to(device)
            outputs = model(imgs)
            probs = F.softmax(outputs, dim=1)  # í™•ë¥ ê°’
            all_probs.append(probs.cpu().numpy())
            filenames.extend(fnames)

    all_probs = np.concatenate(all_probs, axis=0)
    
    # íŒŒì¼ëª…ì„ IDë¡œ ë°”ê¾¸ëŠ” ë¶€ë¶„ (ì˜ˆ: "TEST_00000" í˜•íƒœ)
    ids = [os.path.splitext(f)[0] for f in filenames]  # íŒŒì¼ëª…ì—ì„œ .jpg ë“± ì œê±°
    # ë§Œì•½ IDê°€ íŠ¹ì • í˜•ì‹ì´ë©´ ì—¬ê¸°ì„œ ì¡°ì •

    df = pd.DataFrame(all_probs, columns=class_names)
    df.insert(0, "ID", ids)

    df.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"ì €ì¥ ì™„ë£Œ: {output_csv}")

def plot_training(train_losses, val_losses, val_accuracies, save_path="img/"):
    import matplotlib.pyplot as plt

    epochs = range(1, len(train_losses)+1)
    plt.figure(figsize=(12, 5))

    # ì†ì‹¤ ê·¸ë˜í”„
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label='Train Loss')
    plt.plot(epochs, val_losses, label='Val Loss')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Loss over Epochs")
    plt.legend()

    # ì •í™•ë„ ê·¸ë˜í”„
    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label='Val Accuracy')
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy (%)")
    plt.title("Validation Accuracy over Epochs")
    plt.legend()

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path)
        print(f"ğŸ“ˆ í•™ìŠµ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
    plt.show()

# ì¡°ê¸° ì¢…ë£Œ
class EarlyStopping:
    def __init__(self, patience=5, verbose=True, save_path="best_model.pt"):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        self.save_path = save_path

    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss >= self.best_loss:
            self.counter += 1
            if self.verbose:
                print(f"ğŸ’¤ EarlyStopping counter: {self.counter} / {self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.save_checkpoint(model)
            self.counter = 0

    def save_checkpoint(self, model):
        torch.save(model.state_dict(), self.save_path)
        if self.verbose:
            print(f"âœ… Best model saved to {self.save_path}")

# í˜¼ë™ í–‰ë ¬
def plot_confusion_matrix(model, data_loader, device, class_names, normalize='true', title="Confusion Matrix", save_path="img/confusion_matrix.png"):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    cm = confusion_matrix(all_labels, all_preds, normalize=normalize)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)

    fig, ax = plt.subplots(figsize=(8, 6))
    disp.plot(ax=ax, cmap='Blues', values_format=".2f")
    plt.title(title)

    if save_path:
        plt.savefig(save_path)
        print(f"âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: {save_path}")
    plt.show()

class TestImageDataset(Dataset):
    def __init__(self, folder, transform=None):
        self.paths = sorted([
            os.path.join(folder, f) for f in os.listdir(folder)
            if f.lower().endswith(('.png', '.jpg', '.jpeg'))
        ])
        self.transform = transform

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, os.path.basename(self.paths[idx])



def analyze_noisy_samples_with_filenames(model, data_loader, device, class_names, out_dir="noisy_samples", top_k=50):
    model.eval()
    results = []
    image_dir = os.path.join(out_dir, "images")
    os.makedirs(image_dir, exist_ok=True)
    os.makedirs(out_dir, exist_ok=True)

    with torch.no_grad():
        for batch in tqdm(data_loader):
            # (ì´ë¯¸ì§€, ë¼ë²¨, íŒŒì¼ëª…)
            imgs, labels, filenames = batch
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            losses = F.cross_entropy(outputs, labels, reduction='none')
            probs = F.softmax(outputs, dim=1)

            for i in range(len(labels)):
                results.append({
                    "img_tensor": imgs[i].cpu(),
                    "filename": filenames[i],
                    "true_label": class_names[labels[i].item()],
                    "true_label_idx": labels[i].item(),
                    "pred_label": class_names[probs[i].argmax().item()],
                    "pred_label_idx": probs[i].argmax().item(),
                    "loss": losses[i].item(),
                    "probs": ";".join(map(str, probs[i].cpu().numpy()))
                })

    # loss ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
    results = sorted(results, key=lambda x: x["loss"], reverse=True)[:top_k]

    # ì´ë¯¸ì§€ ë° CSV ì €ì¥ (ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©)
    csv_rows = []
    for sample in results:
        save_path = os.path.join(image_dir, sample["filename"])
        save_image(sample["img_tensor"], save_path)
        row = {
            "img_path": save_path,
            "filename": sample["filename"],
            "true_label": sample["true_label"],
            "true_label_idx": sample["true_label_idx"],
            "pred_label": sample["pred_label"],
            "pred_label_idx": sample["pred_label_idx"],
            "loss": sample["loss"],
            "probs": sample["probs"]
        }
        csv_rows.append(row)

    # CSV ì €ì¥
    df = pd.DataFrame(csv_rows)
    csv_path = os.path.join(out_dir, f"noisy_samples_top{top_k}.csv")
    df.to_csv(csv_path, index=False)
    print(f"CSV ë° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {csv_path}")

    return df

class ImageFolderWithPaths(ImageFolder):
    def __getitem__(self, index):
        original_tuple = super().__getitem__(index)  # (image, label)
        path = self.samples[index][0]
        filename = os.path.basename(path)
        return original_tuple + (filename,)